{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ff51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Set, Iterable\n",
    "import math\n",
    "import time\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gammaincc\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb87e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class ACLDConfig:\n",
    "    # --- timing ---\n",
    "    dt_ctrl: float = 0.05\n",
    "    dt_sim: float = 0.05\n",
    "\n",
    "    # --- swarm ---\n",
    "    n_uavs: int = 150\n",
    "    include_ground_station: bool = True\n",
    "    ground_station_pos: np.ndarray = field(default_factory=lambda: np.array([0.0, 0.0, 0.0], dtype=float))\n",
    "\n",
    "    # --- physical limits ---\n",
    "    v_max: float = 23.0\n",
    "    a_max: float = 60.0\n",
    "    j_max: float = 100.0\n",
    "    d_safe: float = 2.0  # collision-avoidance minimum separation (example)\n",
    "\n",
    "    # --- channel (default UAV-UAV) ---\n",
    "    m_fading: float = 2.5\n",
    "    snr_0_db: float = 22.0\n",
    "    d_0: float = 100.0\n",
    "    path_loss_exp: float = 2.4\n",
    "    gamma_0_db: float = 10.0\n",
    "    p_min: float = 0.90\n",
    "\n",
    "    # --- UAV-GS channel profile (paper says Free-space LoS for UAV-GS) ---\n",
    "    gs_m_fading: float = 3.5\n",
    "    gs_snr_0_db: float = 25.0\n",
    "    gs_path_loss_exp: float = 2.0\n",
    "\n",
    "    # --- adaptive gains ---\n",
    "    alpha: float = 0.35\n",
    "    beta: float = 0.10\n",
    "    gamma: float = 0.20\n",
    "    delta: float = 0.10\n",
    "    zeta: float = 0.05\n",
    "\n",
    "    # --- base range ---\n",
    "    cthr_base: float = 100.0\n",
    "\n",
    "    # --- numerical guards ---\n",
    "    min_cthr: float = 5.0\n",
    "    max_cthr_multiplier: float = 2.0\n",
    "    lambda2_partition_threshold: float = 1e-3\n",
    "\n",
    "    # --- energy (optional simple simulation bookkeeping) ---\n",
    "    e_max: float = 1000.0\n",
    "    e_min_frac: float = 0.15\n",
    "\n",
    "    # --- jamming / SINR params ---\n",
    "    # Controlled stress mode: set jnr_db = None (nominal), or e.g. 5 / 15 dB\n",
    "    jnr_db: Optional[float] = None\n",
    "    # For detailed jammer model (optional):\n",
    "    jammer_tx_dbm: Optional[float] = None\n",
    "    jammer_pos: Optional[np.ndarray] = None\n",
    "    jammer_gain_db: float = 0.0\n",
    "    rx_gain_db: float = 0.0\n",
    "    noise_figure_db: float = 6.0\n",
    "    bandwidth_hz: float = 20e6\n",
    "\n",
    "    # --- simulation area ---\n",
    "    density_scale_mode: str = \"medium\"  # \"sparse\" | \"medium\" | \"dense\"\n",
    "    seed: int = 42\n",
    "\n",
    "    @property\n",
    "    def snr_0_lin(self) -> float:\n",
    "        return 10 ** (self.snr_0_db / 10.0)\n",
    "\n",
    "    @property\n",
    "    def gamma_0_lin(self) -> float:\n",
    "        return 10 ** (self.gamma_0_db / 10.0)\n",
    "\n",
    "    @property\n",
    "    def gs_snr_0_lin(self) -> float:\n",
    "        return 10 ** (self.gs_snr_0_db / 10.0)\n",
    "\n",
    "    @property\n",
    "    def n_total(self) -> int:\n",
    "        return self.n_uavs + (1 if self.include_ground_station else 0)\n",
    "\n",
    "    @property\n",
    "    def gs_index(self) -> Optional[int]:\n",
    "        return self.n_uavs if self.include_ground_station else None\n",
    "\n",
    "    def density_half_side(self) -> float:\n",
    "        mode = self.density_scale_mode.lower()\n",
    "        if mode == \"sparse\":\n",
    "            scale = 1.5\n",
    "        elif mode == \"dense\":\n",
    "            scale = 0.3\n",
    "        else:\n",
    "            scale = 0.8  # medium\n",
    "        return scale * self.cthr_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83c4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# State\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class SwarmState:\n",
    "    pos: np.ndarray          # (n,3)\n",
    "    vel: np.ndarray          # (n,3)\n",
    "    acc_cmd: np.ndarray      # (n,3)\n",
    "    jerk: np.ndarray         # (n,3)\n",
    "    energy: np.ndarray       # (n,)\n",
    "    channel_headroom_db: np.ndarray  # (n,)\n",
    "\n",
    "    @staticmethod\n",
    "    def random_init(cfg: ACLDConfig, rng: np.random.Generator) -> \"SwarmState\":\n",
    "        n = cfg.n_uavs\n",
    "        half_side = cfg.density_half_side()\n",
    "\n",
    "        pos = rng.uniform(-half_side, half_side, size=(n, 3))\n",
    "        vel = rng.normal(0.0, cfg.v_max / 4.0, size=(n, 3))\n",
    "        vel = _clip_rows_norm(vel, cfg.v_max)\n",
    "\n",
    "        acc_cmd = rng.normal(0.0, cfg.a_max / 6.0, size=(n, 3))\n",
    "        acc_cmd = _clip_rows_norm(acc_cmd, cfg.a_max)\n",
    "\n",
    "        jerk = rng.normal(0.0, cfg.j_max / 6.0, size=(n, 3))\n",
    "        jerk = _clip_rows_norm(jerk, cfg.j_max)\n",
    "\n",
    "        energy = np.full(n, cfg.e_max, dtype=float)\n",
    "        channel_headroom_db = np.full(n, 0.0, dtype=float)\n",
    "\n",
    "        return SwarmState(\n",
    "            pos=pos.astype(float),\n",
    "            vel=vel.astype(float),\n",
    "            acc_cmd=acc_cmd.astype(float),\n",
    "            jerk=jerk.astype(float),\n",
    "            energy=energy.astype(float),\n",
    "            channel_headroom_db=channel_headroom_db.astype(float),\n",
    "        )\n",
    "\n",
    "    def step_random_kinematics(self, cfg: ACLDConfig, rng: np.random.Generator) -> None:\n",
    "        \"\"\"\n",
    "        Simple bounded kinematics update for Monte-Carlo simulations.\n",
    "        This is a placeholder simulation model, not a flight controller.\n",
    "        \"\"\"\n",
    "        dt = cfg.dt_sim\n",
    "\n",
    "        # Random jerk perturbation\n",
    "        jerk_noise = rng.normal(0.0, cfg.j_max / 20.0, size=self.jerk.shape)\n",
    "        self.jerk = _clip_rows_norm(self.jerk + jerk_noise, cfg.j_max)\n",
    "\n",
    "        # Update control acceleration\n",
    "        self.acc_cmd = _clip_rows_norm(self.acc_cmd + self.jerk * dt, cfg.a_max)\n",
    "\n",
    "        # Update velocity\n",
    "        self.vel = _clip_rows_norm(self.vel + self.acc_cmd * dt, cfg.v_max)\n",
    "\n",
    "        # Update position\n",
    "        self.pos = self.pos + self.vel * dt\n",
    "\n",
    "        # Simple energy bookkeeping\n",
    "        # (Not physically exact; enough for state completeness)\n",
    "        speed = np.linalg.norm(self.vel, axis=1)\n",
    "        acc = np.linalg.norm(self.acc_cmd, axis=1)\n",
    "        power_proxy = 5.0 + 0.2 * speed + 0.02 * acc**2  # arbitrary proxy\n",
    "        self.energy = np.maximum(0.0, self.energy - power_proxy * dt)\n",
    "\n",
    "    def copy(self) -> \"SwarmState\":\n",
    "        return SwarmState(\n",
    "            pos=self.pos.copy(),\n",
    "            vel=self.vel.copy(),\n",
    "            acc_cmd=self.acc_cmd.copy(),\n",
    "            jerk=self.jerk.copy(),\n",
    "            energy=self.energy.copy(),\n",
    "            channel_headroom_db=self.channel_headroom_db.copy(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3b1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Result containers\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class ACLDResult:\n",
    "    A_pred_guaranteed: np.ndarray\n",
    "    A_pred_viable: np.ndarray\n",
    "    d_pred_uav: np.ndarray\n",
    "    d_cur_uav: np.ndarray\n",
    "    theta_minus_uav: np.ndarray\n",
    "    theta_plus_uav: np.ndarray\n",
    "    theta_minus_gs: Optional[np.ndarray]\n",
    "    theta_plus_gs: Optional[np.ndarray]\n",
    "    s_pred_uav: np.ndarray\n",
    "    s_cur_uav: np.ndarray\n",
    "    components: List[Set[int]]\n",
    "    comp_of: Dict[int, int]\n",
    "    risky_inter: List[Tuple[int, int]]\n",
    "    risky_intra: List[Tuple[int, int]]\n",
    "    risky_s_uav: List[Tuple[int, int]]\n",
    "    risky_uav_uav: List[Tuple[int, int]]\n",
    "    lambda2_current: float\n",
    "    lambda2_pred_viable: float\n",
    "    W_current: np.ndarray\n",
    "    L_current: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Core ACLD\n",
    "# ============================================================\n",
    "\n",
    "class ACLDCore:\n",
    "    def __init__(self, cfg: ACLDConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    # --------------------------\n",
    "    # Geometry utilities\n",
    "    # --------------------------\n",
    "    def _pairwise_uav_dist(self, pos: np.ndarray) -> np.ndarray:\n",
    "        return cdist(pos, pos, metric=\"euclidean\")\n",
    "\n",
    "    def _uav_gs_dist(self, pos: np.ndarray) -> np.ndarray:\n",
    "        gs = self.cfg.ground_station_pos.reshape(1, 3)\n",
    "        return np.linalg.norm(pos - gs, axis=1)\n",
    "\n",
    "    def _dispersion_stats(self, d_uav: np.ndarray) -> Tuple[float, float]:\n",
    "        n = d_uav.shape[0]\n",
    "        iu = np.triu_indices(n, k=1)\n",
    "        vals = d_uav[iu]\n",
    "        if vals.size == 0:\n",
    "            return 0.0, 1.0\n",
    "        bar_d = float(np.mean(vals))\n",
    "        sigma_d = float(np.std(vals))\n",
    "        return sigma_d, max(bar_d, 1e-9)\n",
    "\n",
    "    def _heading_diff_matrix(self, vel: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Absolute angle difference in [0, pi] using 3D vectors.\n",
    "        If a vector norm is ~0, angle term defaults to 0 for that pair.\n",
    "        \"\"\"\n",
    "        n = vel.shape[0]\n",
    "        norms = np.linalg.norm(vel, axis=1)\n",
    "        H = np.zeros((n, n), dtype=float)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                ni, nj = norms[i], norms[j]\n",
    "                if ni < 1e-9 or nj < 1e-9:\n",
    "                    ang = 0.0\n",
    "                else:\n",
    "                    c = float(np.dot(vel[i], vel[j]) / (ni * nj))\n",
    "                    c = np.clip(c, -1.0, 1.0)\n",
    "                    ang = float(np.arccos(c))\n",
    "                H[i, j] = H[j, i] = ang\n",
    "        return H\n",
    "\n",
    "    # --------------------------\n",
    "    # Adaptive thresholds\n",
    "    # --------------------------\n",
    "    def adaptive_threshold_uav_uav(\n",
    "        self,\n",
    "        state: SwarmState,\n",
    "        d_uav: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Returns cthr_ij, theta_minus_ij, theta_plus_ij\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "        n = cfg.n_uavs\n",
    "\n",
    "        sigma_d, bar_d = self._dispersion_stats(d_uav)\n",
    "        rel_speed = cdist(state.vel, state.vel, metric=\"euclidean\")\n",
    "        rel_acc = cdist(state.acc_cmd, state.acc_cmd, metric=\"euclidean\")\n",
    "        rel_jerk = cdist(state.jerk, state.jerk, metric=\"euclidean\")\n",
    "        dtheta = self._heading_diff_matrix(state.vel)\n",
    "\n",
    "        term = (\n",
    "            1.0\n",
    "            + cfg.alpha * (sigma_d / bar_d)\n",
    "            - cfg.beta * (rel_speed / (2.0 * cfg.v_max + 1e-12))\n",
    "            - cfg.gamma * (dtheta / math.pi)\n",
    "            - cfg.delta * (rel_acc / (2.0 * cfg.a_max + 1e-12))\n",
    "            - cfg.zeta * (rel_jerk / (2.0 * cfg.j_max + 1e-12))\n",
    "        )\n",
    "        cthr = cfg.cthr_base * term\n",
    "\n",
    "        cthr = np.clip(cthr, cfg.min_cthr, cfg.max_cthr_multiplier * cfg.cthr_base)\n",
    "        np.fill_diagonal(cthr, 0.0)\n",
    "\n",
    "        theta_plus = cthr\n",
    "        theta_minus = 0.9 * cthr\n",
    "        np.fill_diagonal(theta_minus, 0.0)\n",
    "        np.fill_diagonal(theta_plus, 0.0)\n",
    "\n",
    "        return cthr, theta_minus, theta_plus\n",
    "\n",
    "    def adaptive_threshold_uav_gs(self, state: SwarmState, d_uav: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Eq. cthradp_gs in paper (no heading term).\n",
    "        Returns cthr_is, theta_minus_is, theta_plus_is of shape (n_uavs,)\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "        sigma_d, bar_d = self._dispersion_stats(d_uav)\n",
    "\n",
    "        speed = np.linalg.norm(state.vel, axis=1)\n",
    "        acc = np.linalg.norm(state.acc_cmd, axis=1)\n",
    "        jerk = np.linalg.norm(state.jerk, axis=1)\n",
    "\n",
    "        term = (\n",
    "            1.0\n",
    "            + cfg.alpha * (sigma_d / bar_d)\n",
    "            - cfg.beta * (speed / (cfg.v_max + 1e-12))\n",
    "            - cfg.delta * (acc / (cfg.a_max + 1e-12))\n",
    "            - cfg.zeta * (jerk / (cfg.j_max + 1e-12))\n",
    "        )\n",
    "        cthr = cfg.cthr_base * term\n",
    "        cthr = np.clip(cthr, cfg.min_cthr, cfg.max_cthr_multiplier * cfg.cthr_base)\n",
    "        theta_plus = cthr\n",
    "        theta_minus = 0.9 * cthr\n",
    "        return cthr, theta_minus, theta_plus\n",
    "\n",
    "    # --------------------------\n",
    "    # Channel model (Nakagami-m)\n",
    "    # --------------------------\n",
    "    def _nb_dbm(self) -> float:\n",
    "        cfg = self.cfg\n",
    "        return -174.0 + 10.0 * math.log10(cfg.bandwidth_hz) + cfg.noise_figure_db\n",
    "\n",
    "    def _detailed_jnr_db_per_receiver(self, pos: np.ndarray) -> Optional[np.ndarray]:\n",
    "        cfg = self.cfg\n",
    "        if cfg.jammer_tx_dbm is None or cfg.jammer_pos is None:\n",
    "            return None\n",
    "\n",
    "        nb_dbm = self._nb_dbm()\n",
    "        d = np.linalg.norm(pos - cfg.jammer_pos.reshape(1, 3), axis=1)\n",
    "        d = np.maximum(d, 1.0)\n",
    "\n",
    "        # Simple log-distance path loss (consistent enough for stress simulation)\n",
    "        pl_db = 20.0 * np.log10(4 * np.pi * cfg.d_0 / 0.0517) + 10.0 * cfg.path_loss_exp * np.log10(d / cfg.d_0)\n",
    "        p_rx_j_dbm = cfg.jammer_tx_dbm + cfg.jammer_gain_db + cfg.rx_gain_db - pl_db\n",
    "        jnr_db = p_rx_j_dbm - nb_dbm\n",
    "        return jnr_db\n",
    "\n",
    "    def _receiver_jnr_lin(self, pos: np.ndarray) -> Optional[np.ndarray]:\n",
    "        cfg = self.cfg\n",
    "\n",
    "        if cfg.jnr_db is not None:\n",
    "            # controlled receiver-referenced stress (paper-friendly)\n",
    "            return np.full(cfg.n_uavs, 10 ** (cfg.jnr_db / 10.0), dtype=float)\n",
    "\n",
    "        jnr_db_per_rx = self._detailed_jnr_db_per_receiver(pos)\n",
    "        if jnr_db_per_rx is None:\n",
    "            return None\n",
    "        return 10 ** (jnr_db_per_rx / 10.0)\n",
    "\n",
    "    def _nakagami_success_from_mean_snr(self, mean_snr: np.ndarray, m: float) -> np.ndarray:\n",
    "        cfg = self.cfg\n",
    "        x = m * (cfg.gamma_0_lin / np.maximum(mean_snr, 1e-12))\n",
    "        # Γ(m,x)/Γ(m) = gammaincc(m,x)\n",
    "        s = gammaincc(m, x)\n",
    "        return np.clip(s, 0.0, 1.0)\n",
    "\n",
    "    def success_probability_uav_uav(self, d_uav: np.ndarray, pos_for_jammer: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        cfg = self.cfg\n",
    "        d = np.maximum(d_uav, 1e-9)\n",
    "\n",
    "        mean_snr = cfg.snr_0_lin * (cfg.d_0 / d) ** cfg.path_loss_exp\n",
    "\n",
    "        # Jamming-aware SINR if configured\n",
    "        if pos_for_jammer is None:\n",
    "            pos_for_jammer = None\n",
    "\n",
    "        jnr_lin_per_rx = None\n",
    "        if pos_for_jammer is not None:\n",
    "            jnr_lin_per_rx = self._receiver_jnr_lin(pos_for_jammer)\n",
    "\n",
    "        if jnr_lin_per_rx is not None:\n",
    "            # conservative link-level j_lin_ij = max(j_i, j_j)\n",
    "            ji = jnr_lin_per_rx.reshape(-1, 1)\n",
    "            jj = jnr_lin_per_rx.reshape(1, -1)\n",
    "            j_lin_ij = np.maximum(ji, jj)\n",
    "            mean_snr = mean_snr / (1.0 + j_lin_ij)\n",
    "\n",
    "        s = self._nakagami_success_from_mean_snr(mean_snr, cfg.m_fading)\n",
    "        np.fill_diagonal(s, 0.0)\n",
    "        return s\n",
    "\n",
    "    def success_probability_uav_gs(self, d_gs: np.ndarray, pos: np.ndarray) -> np.ndarray:\n",
    "        cfg = self.cfg\n",
    "        d = np.maximum(d_gs, 1e-9)\n",
    "\n",
    "        mean_snr = cfg.gs_snr_0_lin * (cfg.d_0 / d) ** cfg.gs_path_loss_exp\n",
    "\n",
    "        jnr_lin_per_rx = self._receiver_jnr_lin(pos)\n",
    "        if jnr_lin_per_rx is not None:\n",
    "            # receiver is UAV i for UAV-GS link\n",
    "            mean_snr = mean_snr / (1.0 + jnr_lin_per_rx)\n",
    "\n",
    "        s = self._nakagami_success_from_mean_snr(mean_snr, cfg.gs_m_fading)\n",
    "        return np.clip(s, 0.0, 1.0)\n",
    "\n",
    "    # --------------------------\n",
    "    # Predicted adjacency / risk sets\n",
    "    # --------------------------\n",
    "    def _predict_positions_one_step(self, state: SwarmState) -> np.ndarray:\n",
    "        return state.pos + state.vel * self.cfg.dt_ctrl\n",
    "\n",
    "    def _build_pred_matrices(\n",
    "        self, state: SwarmState\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          d_cur_uav, d_pred_uav,\n",
    "          theta_minus_uav, theta_plus_uav,\n",
    "          s_cur_uav, s_pred_uav,\n",
    "          d_cur_gs, d_pred_gs, theta_minus_gs, theta_plus_gs\n",
    "        \"\"\"\n",
    "        d_cur_uav = self._pairwise_uav_dist(state.pos)\n",
    "        pred_pos = self._predict_positions_one_step(state)\n",
    "        d_pred_uav = self._pairwise_uav_dist(pred_pos)\n",
    "\n",
    "        _, theta_minus_uav, theta_plus_uav = self.adaptive_threshold_uav_uav(state, d_cur_uav)\n",
    "\n",
    "        s_cur_uav = self.success_probability_uav_uav(d_cur_uav, pos_for_jammer=state.pos)\n",
    "        s_pred_uav = self.success_probability_uav_uav(d_pred_uav, pos_for_jammer=pred_pos)\n",
    "\n",
    "        if self.cfg.include_ground_station:\n",
    "            d_cur_gs = self._uav_gs_dist(state.pos)\n",
    "            d_pred_gs = self._uav_gs_dist(pred_pos)\n",
    "            _, theta_minus_gs, theta_plus_gs = self.adaptive_threshold_uav_gs(state, d_cur_uav)\n",
    "        else:\n",
    "            d_cur_gs = d_pred_gs = theta_minus_gs = theta_plus_gs = None\n",
    "\n",
    "        return (\n",
    "            d_cur_uav, d_pred_uav,\n",
    "            theta_minus_uav, theta_plus_uav,\n",
    "            s_cur_uav, s_pred_uav,\n",
    "            d_cur_gs, d_pred_gs, theta_minus_gs, theta_plus_gs\n",
    "        )\n",
    "\n",
    "    def _build_pred_adjacency(\n",
    "        self,\n",
    "        d_pred_uav: np.ndarray,\n",
    "        theta_minus_uav: np.ndarray,\n",
    "        theta_plus_uav: np.ndarray,\n",
    "        s_pred_uav: np.ndarray,\n",
    "        d_pred_gs: Optional[np.ndarray],\n",
    "        theta_minus_gs: Optional[np.ndarray],\n",
    "        theta_plus_gs: Optional[np.ndarray],\n",
    "        s_pred_gs: Optional[np.ndarray],\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Build predicted guaranteed and viable adjacency on V' (including GS if enabled).\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "        n_uav = cfg.n_uavs\n",
    "        n_total = cfg.n_total\n",
    "\n",
    "        A_minus = np.zeros((n_total, n_total), dtype=np.uint8)\n",
    "        A_plus = np.zeros((n_total, n_total), dtype=np.uint8)\n",
    "\n",
    "        # UAV-UAV edges\n",
    "        viable_uav = (d_pred_uav <= theta_plus_uav) & (s_pred_uav >= cfg.p_min)\n",
    "        guar_uav = (d_pred_uav <= theta_minus_uav) & (s_pred_uav >= cfg.p_min)\n",
    "\n",
    "        np.fill_diagonal(viable_uav, False)\n",
    "        np.fill_diagonal(guar_uav, False)\n",
    "\n",
    "        A_plus[:n_uav, :n_uav] = viable_uav.astype(np.uint8)\n",
    "        A_minus[:n_uav, :n_uav] = guar_uav.astype(np.uint8)\n",
    "\n",
    "        # UAV-GS edges\n",
    "        if cfg.include_ground_station:\n",
    "            assert d_pred_gs is not None and theta_plus_gs is not None and theta_minus_gs is not None and s_pred_gs is not None\n",
    "            sidx = cfg.gs_index\n",
    "            viable_gs = (d_pred_gs <= theta_plus_gs) & (s_pred_gs >= cfg.p_min)\n",
    "            guar_gs = (d_pred_gs <= theta_minus_gs) & (s_pred_gs >= cfg.p_min)\n",
    "\n",
    "            for i in range(n_uav):\n",
    "                if viable_gs[i]:\n",
    "                    A_plus[i, sidx] = 1\n",
    "                    A_plus[sidx, i] = 1\n",
    "                if guar_gs[i]:\n",
    "                    A_minus[i, sidx] = 1\n",
    "                    A_minus[sidx, i] = 1\n",
    "\n",
    "        return A_minus, A_plus\n",
    "\n",
    "    # --------------------------\n",
    "    # Pseudocode-equivalent graph routines\n",
    "    # --------------------------\n",
    "    @staticmethod\n",
    "    def _adj_list_from_adjacency(A: np.ndarray) -> List[List[int]]:\n",
    "        n = A.shape[0]\n",
    "        adj = []\n",
    "        for i in range(n):\n",
    "            adj.append(np.flatnonzero(A[i]).tolist())\n",
    "        return adj\n",
    "\n",
    "    @staticmethod\n",
    "    def kneighbors(adj: List[List[int]], seed: int, k_max: int) -> Set[int]:\n",
    "        seen: Set[int] = {seed}\n",
    "        q: List[Tuple[int, int]] = [(seed, 0)]\n",
    "        head = 0\n",
    "        while head < len(q):\n",
    "            u, depth = q[head]\n",
    "            head += 1\n",
    "            if depth == k_max:\n",
    "                continue\n",
    "            for v in adj[u]:\n",
    "                if v not in seen:\n",
    "                    seen.add(v)\n",
    "                    q.append((v, depth + 1))\n",
    "        return seen\n",
    "\n",
    "    @classmethod\n",
    "    def predict_components(cls, A_guaranteed: np.ndarray, k_max: Optional[int] = None) -> Tuple[List[Set[int]], Dict[int, int]]:\n",
    "        n = A_guaranteed.shape[0]\n",
    "        if k_max is None:\n",
    "            k_max = n  # full BFS as in manuscript note\n",
    "\n",
    "        adj = cls._adj_list_from_adjacency(A_guaranteed)\n",
    "\n",
    "        unseen = set(range(n))\n",
    "        comps: List[Set[int]] = []\n",
    "        comp_of: Dict[int, int] = {}\n",
    "\n",
    "        while unseen:\n",
    "            i = next(iter(unseen))\n",
    "            C = cls.kneighbors(adj, i, k_max=k_max)\n",
    "            idx = len(comps)\n",
    "            for u in C:\n",
    "                comp_of[u] = idx\n",
    "            comps.append(C)\n",
    "            unseen -= C\n",
    "\n",
    "        return comps, comp_of\n",
    "\n",
    "    @staticmethod\n",
    "    def catalogue_risky_links(\n",
    "        A_pred_viable: np.ndarray,\n",
    "        comp_of: Dict[int, int],\n",
    "        cfg: ACLDConfig,\n",
    "        d_pred_uav: np.ndarray,\n",
    "        theta_minus_uav: np.ndarray,\n",
    "        theta_plus_uav: np.ndarray,\n",
    "        d_pred_gs: Optional[np.ndarray],\n",
    "        theta_minus_gs: Optional[np.ndarray],\n",
    "        theta_plus_gs: Optional[np.ndarray],\n",
    "    ) -> Tuple[List[Tuple[int, int]], List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Risk-band = viable but not guaranteed (theta_minus < d <= theta_plus, and viable already ensured).\n",
    "        Returns (inter, intra)\n",
    "        \"\"\"\n",
    "        n_total = A_pred_viable.shape[0]\n",
    "        n_uav = cfg.n_uavs\n",
    "        sidx = cfg.gs_index\n",
    "\n",
    "        inter: List[Tuple[int, int]] = []\n",
    "        intra: List[Tuple[int, int]] = []\n",
    "\n",
    "        for i in range(n_total):\n",
    "            for j in range(i + 1, n_total):\n",
    "                if A_pred_viable[i, j] == 0:\n",
    "                    continue\n",
    "\n",
    "                in_risk_band = False\n",
    "\n",
    "                if i < n_uav and j < n_uav:\n",
    "                    dij = d_pred_uav[i, j]\n",
    "                    if theta_minus_uav[i, j] < dij <= theta_plus_uav[i, j]:\n",
    "                        in_risk_band = True\n",
    "                else:\n",
    "                    # UAV-GS case\n",
    "                    if sidx is None:\n",
    "                        continue\n",
    "                    if d_pred_gs is None or theta_minus_gs is None or theta_plus_gs is None:\n",
    "                        continue\n",
    "                    u = i if j == sidx else j if i == sidx else None\n",
    "                    if u is not None and 0 <= u < n_uav:\n",
    "                        du = d_pred_gs[u]\n",
    "                        if theta_minus_gs[u] < du <= theta_plus_gs[u]:\n",
    "                            in_risk_band = True\n",
    "\n",
    "                if not in_risk_band:\n",
    "                    continue\n",
    "\n",
    "                if comp_of.get(i, -1) != comp_of.get(j, -1):\n",
    "                    inter.append((i, j))\n",
    "                else:\n",
    "                    intra.append((i, j))\n",
    "\n",
    "        return inter, intra\n",
    "\n",
    "    @staticmethod\n",
    "    def separate_ground_links(\n",
    "        risky_inter: List[Tuple[int, int]],\n",
    "        gs_index: Optional[int]\n",
    "    ) -> Tuple[List[Tuple[int, int]], List[Tuple[int, int]]]:\n",
    "        if gs_index is None:\n",
    "            return [], risky_inter.copy()\n",
    "\n",
    "        s_uav: List[Tuple[int, int]] = []\n",
    "        uav_uav: List[Tuple[int, int]] = []\n",
    "\n",
    "        for i, j in risky_inter:\n",
    "            if i == gs_index or j == gs_index:\n",
    "                s_uav.append((i, j))\n",
    "            else:\n",
    "                uav_uav.append((i, j))\n",
    "        return s_uav, uav_uav\n",
    "\n",
    "    # --------------------------\n",
    "    # Weighted graph / Laplacian / lambda2\n",
    "    # --------------------------\n",
    "    def _build_current_weighted_graph(self, state: SwarmState) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Build W and L on current channel-viable graph G_viable(t), including GS if enabled.\n",
    "        Uses geometric candidates + viability guard + directed row-stochastic inverse-square weights + symmetrization.\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "        n_uav = cfg.n_uavs\n",
    "        n_total = cfg.n_total\n",
    "        sidx = cfg.gs_index\n",
    "\n",
    "        d_cur_uav = self._pairwise_uav_dist(state.pos)\n",
    "        _, theta_minus_uav, theta_plus_uav = self.adaptive_threshold_uav_uav(state, d_cur_uav)\n",
    "        s_cur_uav = self.success_probability_uav_uav(d_cur_uav, pos_for_jammer=state.pos)\n",
    "\n",
    "        d_cur_gs = theta_minus_gs = theta_plus_gs = s_cur_gs = None\n",
    "        if cfg.include_ground_station:\n",
    "            d_cur_gs = self._uav_gs_dist(state.pos)\n",
    "            _, theta_minus_gs, theta_plus_gs = self.adaptive_threshold_uav_gs(state, d_cur_uav)\n",
    "            s_cur_gs = self.success_probability_uav_gs(d_cur_gs, state.pos)\n",
    "\n",
    "        W_tilde = np.zeros((n_total, n_total), dtype=float)\n",
    "\n",
    "        # UAV rows\n",
    "        for i in range(n_uav):\n",
    "            neighbors: List[Tuple[int, float]] = []\n",
    "\n",
    "            # UAV-UAV viable neighbors\n",
    "            for j in range(n_uav):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if d_cur_uav[i, j] <= theta_plus_uav[i, j] and s_cur_uav[i, j] >= cfg.p_min:\n",
    "                    neighbors.append((j, max(d_cur_uav[i, j], cfg.d_safe)))\n",
    "\n",
    "            # UAV-GS viable neighbor\n",
    "            if cfg.include_ground_station and d_cur_gs is not None and theta_plus_gs is not None and s_cur_gs is not None:\n",
    "                if d_cur_gs[i] <= theta_plus_gs[i] and s_cur_gs[i] >= cfg.p_min:\n",
    "                    neighbors.append((sidx, max(d_cur_gs[i], cfg.d_safe)))\n",
    "\n",
    "            if len(neighbors) == 0:\n",
    "                continue\n",
    "\n",
    "            invsq = np.array([1.0 / (d * d) for _, d in neighbors], dtype=float)\n",
    "            denom = float(np.sum(invsq))\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "\n",
    "            for (k, _d), w in zip(neighbors, invsq / denom):\n",
    "                W_tilde[i, k] = float(w)\n",
    "\n",
    "        # GS row (if present)\n",
    "        if cfg.include_ground_station and sidx is not None and d_cur_gs is not None and theta_plus_gs is not None and s_cur_gs is not None:\n",
    "            neighbors_gs: List[Tuple[int, float]] = []\n",
    "            for i in range(n_uav):\n",
    "                if d_cur_gs[i] <= theta_plus_gs[i] and s_cur_gs[i] >= cfg.p_min:\n",
    "                    neighbors_gs.append((i, max(d_cur_gs[i], cfg.d_safe)))\n",
    "\n",
    "            if neighbors_gs:\n",
    "                invsq = np.array([1.0 / (d * d) for _, d in neighbors_gs], dtype=float)\n",
    "                denom = float(np.sum(invsq))\n",
    "                if denom > 0:\n",
    "                    for (i, _d), w in zip(neighbors_gs, invsq / denom):\n",
    "                        W_tilde[sidx, i] = float(w)\n",
    "\n",
    "        # Symmetrize\n",
    "        W = 0.5 * (W_tilde + W_tilde.T)\n",
    "        np.fill_diagonal(W, 0.0)\n",
    "\n",
    "        D = np.diag(np.sum(W, axis=1))\n",
    "        L = D - W\n",
    "        return W, D, L\n",
    "\n",
    "    @staticmethod\n",
    "    def algebraic_connectivity_lambda2(L: np.ndarray) -> float:\n",
    "        n = L.shape[0]\n",
    "        if n <= 1:\n",
    "            return 0.0\n",
    "        # Dense eigvalsh is acceptable up to n~1000 in this context\n",
    "        evals = np.linalg.eigvalsh(L)\n",
    "        evals = np.sort(np.real(evals))\n",
    "        if len(evals) < 2:\n",
    "            return 0.0\n",
    "        return float(max(0.0, evals[1]))\n",
    "\n",
    "    # --------------------------\n",
    "    # Baselines\n",
    "    # --------------------------\n",
    "    @staticmethod\n",
    "    def tarjan_bridges(A: np.ndarray) -> List[Tuple[int, int]]:\n",
    "        n = A.shape[0]\n",
    "        adj = ACLDCore._adj_list_from_adjacency(A)\n",
    "\n",
    "        disc = [-1] * n\n",
    "        low = [-1] * n\n",
    "        parent = [-1] * n\n",
    "        time_counter = 0\n",
    "        bridges: List[Tuple[int, int]] = []\n",
    "\n",
    "        def dfs(u: int) -> None:\n",
    "            nonlocal time_counter\n",
    "            disc[u] = low[u] = time_counter\n",
    "            time_counter += 1\n",
    "\n",
    "            for v in adj[u]:\n",
    "                if disc[v] == -1:\n",
    "                    parent[v] = u\n",
    "                    dfs(v)\n",
    "                    low[u] = min(low[u], low[v])\n",
    "\n",
    "                    if low[v] > disc[u]:\n",
    "                        bridges.append((u, v) if u < v else (v, u))\n",
    "                elif v != parent[u]:\n",
    "                    low[u] = min(low[u], disc[v])\n",
    "\n",
    "        for i in range(n):\n",
    "            if disc[i] == -1:\n",
    "                dfs(i)\n",
    "\n",
    "        bridges = sorted(set(bridges))\n",
    "        return bridges\n",
    "\n",
    "    @staticmethod\n",
    "    def edge_betweenness_brandes_unweighted(A: np.ndarray) -> Dict[Tuple[int, int], float]:\n",
    "        \"\"\"\n",
    "        Exact Brandes edge betweenness for unweighted undirected graph.\n",
    "        \"\"\"\n",
    "        n = A.shape[0]\n",
    "        adj = ACLDCore._adj_list_from_adjacency(A)\n",
    "        eb: Dict[Tuple[int, int], float] = {}\n",
    "\n",
    "        for s in range(n):\n",
    "            stack: List[int] = []\n",
    "            pred: List[List[int]] = [[] for _ in range(n)]\n",
    "            sigma = np.zeros(n, dtype=float)\n",
    "            dist = -np.ones(n, dtype=int)\n",
    "\n",
    "            sigma[s] = 1.0\n",
    "            dist[s] = 0\n",
    "\n",
    "            # BFS\n",
    "            q = [s]\n",
    "            qh = 0\n",
    "            while qh < len(q):\n",
    "                v = q[qh]\n",
    "                qh += 1\n",
    "                stack.append(v)\n",
    "                for w in adj[v]:\n",
    "                    if dist[w] < 0:\n",
    "                        q.append(w)\n",
    "                        dist[w] = dist[v] + 1\n",
    "                    if dist[w] == dist[v] + 1:\n",
    "                        sigma[w] += sigma[v]\n",
    "                        pred[w].append(v)\n",
    "\n",
    "            delta = np.zeros(n, dtype=float)\n",
    "            while stack:\n",
    "                w = stack.pop()\n",
    "                for v in pred[w]:\n",
    "                    if sigma[w] > 0:\n",
    "                        c = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n",
    "                    else:\n",
    "                        c = 0.0\n",
    "                    e = (v, w) if v < w else (w, v)\n",
    "                    eb[e] = eb.get(e, 0.0) + c\n",
    "                    delta[v] += c\n",
    "\n",
    "        # undirected graph correction\n",
    "        for e in list(eb.keys()):\n",
    "            eb[e] *= 0.5\n",
    "        return eb\n",
    "\n",
    "    def baseline_tarjan_snapshot(self, state: SwarmState, with_guard: bool = True) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        TARJAN@t: snapshot bridges on current graph.\n",
    "        If with_guard=False, geometry only (cthr+ band) without probabilistic guard.\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "        n_total = cfg.n_total\n",
    "        n_uav = cfg.n_uavs\n",
    "        sidx = cfg.gs_index\n",
    "\n",
    "        d_cur_uav = self._pairwise_uav_dist(state.pos)\n",
    "        _, _, theta_plus_uav = self.adaptive_threshold_uav_uav(state, d_cur_uav)\n",
    "        s_cur_uav = self.success_probability_uav_uav(d_cur_uav, pos_for_jammer=state.pos)\n",
    "\n",
    "        A = np.zeros((n_total, n_total), dtype=np.uint8)\n",
    "\n",
    "        mask_uav = (d_cur_uav <= theta_plus_uav)\n",
    "        if with_guard:\n",
    "            mask_uav &= (s_cur_uav >= cfg.p_min)\n",
    "        np.fill_diagonal(mask_uav, False)\n",
    "        A[:n_uav, :n_uav] = mask_uav.astype(np.uint8)\n",
    "\n",
    "        if cfg.include_ground_station:\n",
    "            d_cur_gs = self._uav_gs_dist(state.pos)\n",
    "            _, _, theta_plus_gs = self.adaptive_threshold_uav_gs(state, d_cur_uav)\n",
    "            s_cur_gs = self.success_probability_uav_gs(d_cur_gs, state.pos)\n",
    "\n",
    "            for i in range(n_uav):\n",
    "                ok = d_cur_gs[i] <= theta_plus_gs[i]\n",
    "                if with_guard:\n",
    "                    ok = ok and (s_cur_gs[i] >= cfg.p_min)\n",
    "                if ok:\n",
    "                    A[i, sidx] = A[sidx, i] = 1\n",
    "\n",
    "        return self.tarjan_bridges(A)\n",
    "\n",
    "    # --------------------------\n",
    "    # Main ACLD step\n",
    "    # --------------------------\n",
    "    def run_acld(self, state: SwarmState) -> ACLDResult:\n",
    "        cfg = self.cfg\n",
    "\n",
    "        (\n",
    "            d_cur_uav, d_pred_uav,\n",
    "            theta_minus_uav, theta_plus_uav,\n",
    "            s_cur_uav, s_pred_uav,\n",
    "            d_cur_gs, d_pred_gs, theta_minus_gs, theta_plus_gs\n",
    "        ) = self._build_pred_matrices(state)\n",
    "\n",
    "        s_pred_gs = None\n",
    "        if cfg.include_ground_station and d_pred_gs is not None:\n",
    "            pred_pos = self._predict_positions_one_step(state)\n",
    "            s_pred_gs = self.success_probability_uav_gs(d_pred_gs, pred_pos)\n",
    "\n",
    "        A_pred_guaranteed, A_pred_viable = self._build_pred_adjacency(\n",
    "            d_pred_uav=d_pred_uav,\n",
    "            theta_minus_uav=theta_minus_uav,\n",
    "            theta_plus_uav=theta_plus_uav,\n",
    "            s_pred_uav=s_pred_uav,\n",
    "            d_pred_gs=d_pred_gs,\n",
    "            theta_minus_gs=theta_minus_gs,\n",
    "            theta_plus_gs=theta_plus_gs,\n",
    "            s_pred_gs=s_pred_gs,\n",
    "        )\n",
    "\n",
    "        components, comp_of = self.predict_components(A_pred_guaranteed, k_max=cfg.n_total)\n",
    "\n",
    "        risky_inter, risky_intra = self.catalogue_risky_links(\n",
    "            A_pred_viable=A_pred_viable,\n",
    "            comp_of=comp_of,\n",
    "            cfg=cfg,\n",
    "            d_pred_uav=d_pred_uav,\n",
    "            theta_minus_uav=theta_minus_uav,\n",
    "            theta_plus_uav=theta_plus_uav,\n",
    "            d_pred_gs=d_pred_gs,\n",
    "            theta_minus_gs=theta_minus_gs,\n",
    "            theta_plus_gs=theta_plus_gs,\n",
    "        )\n",
    "\n",
    "        risky_s_uav, risky_uav_uav = self.separate_ground_links(risky_inter, cfg.gs_index)\n",
    "\n",
    "        W_current, D_current, L_current = self._build_current_weighted_graph(state)\n",
    "        lambda2_current = self.algebraic_connectivity_lambda2(L_current)\n",
    "\n",
    "        # predicted viable Laplacian (binary) for diagnostic only\n",
    "        D_pred = np.diag(np.sum(A_pred_viable.astype(float), axis=1))\n",
    "        L_pred_viable = D_pred - A_pred_viable.astype(float)\n",
    "        lambda2_pred_viable = self.algebraic_connectivity_lambda2(L_pred_viable)\n",
    "\n",
    "        return ACLDResult(\n",
    "            A_pred_guaranteed=A_pred_guaranteed,\n",
    "            A_pred_viable=A_pred_viable,\n",
    "            d_pred_uav=d_pred_uav,\n",
    "            d_cur_uav=d_cur_uav,\n",
    "            theta_minus_uav=theta_minus_uav,\n",
    "            theta_plus_uav=theta_plus_uav,\n",
    "            theta_minus_gs=theta_minus_gs,\n",
    "            theta_plus_gs=theta_plus_gs,\n",
    "            s_pred_uav=s_pred_uav,\n",
    "            s_cur_uav=s_cur_uav,\n",
    "            components=components,\n",
    "            comp_of=comp_of,\n",
    "            risky_inter=risky_inter,\n",
    "            risky_intra=risky_intra,\n",
    "            risky_s_uav=risky_s_uav,\n",
    "            risky_uav_uav=risky_uav_uav,\n",
    "            lambda2_current=lambda2_current,\n",
    "            lambda2_pred_viable=lambda2_pred_viable,\n",
    "            W_current=W_current,\n",
    "            L_current=L_current,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Simulation / Evaluation helpers\n",
    "# ============================================================\n",
    "\n",
    "def _clip_rows_norm(X: np.ndarray, max_norm: float) -> np.ndarray:\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    scale = np.ones_like(norms)\n",
    "    mask = norms > max_norm\n",
    "    scale[mask] = max_norm / np.maximum(norms[mask], 1e-12)\n",
    "    return X * scale\n",
    "\n",
    "\n",
    "def make_rng(seed: int) -> np.random.Generator:\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StepLog:\n",
    "    t: float\n",
    "    lambda2_current: float\n",
    "    partition_now: bool\n",
    "    n_components_pred_guar: int\n",
    "    n_risky_inter: int\n",
    "    n_risky_intra: int\n",
    "    n_risky_s_uav: int\n",
    "    n_risky_uav_uav: int\n",
    "    runtime_ms: float\n",
    "\n",
    "\n",
    "def run_episode(\n",
    "    cfg: ACLDConfig,\n",
    "    horizon_s: float = 10.0,\n",
    "    seed: Optional[int] = None,\n",
    ") -> Tuple[List[StepLog], List[ACLDResult]]:\n",
    "    rng = make_rng(cfg.seed if seed is None else seed)\n",
    "    state = SwarmState.random_init(cfg, rng)\n",
    "    acld = ACLDCore(cfg)\n",
    "\n",
    "    T = int(round(horizon_s / cfg.dt_sim))\n",
    "    logs: List[StepLog] = []\n",
    "    results: List[ACLDResult] = []\n",
    "\n",
    "    t_now = 0.0\n",
    "    for _ in range(T):\n",
    "        t0 = time.perf_counter()\n",
    "        res = acld.run_acld(state)\n",
    "        t1 = time.perf_counter()\n",
    "        runtime_ms = (t1 - t0) * 1000.0\n",
    "\n",
    "        partition_now = res.lambda2_current < cfg.lambda2_partition_threshold\n",
    "        logs.append(\n",
    "            StepLog(\n",
    "                t=t_now,\n",
    "                lambda2_current=res.lambda2_current,\n",
    "                partition_now=partition_now,\n",
    "                n_components_pred_guar=len(res.components),\n",
    "                n_risky_inter=len(res.risky_inter),\n",
    "                n_risky_intra=len(res.risky_intra),\n",
    "                n_risky_s_uav=len(res.risky_s_uav),\n",
    "                n_risky_uav_uav=len(res.risky_uav_uav),\n",
    "                runtime_ms=runtime_ms,\n",
    "            )\n",
    "        )\n",
    "        results.append(res)\n",
    "\n",
    "        # Advance simulation\n",
    "        state.step_random_kinematics(cfg, rng)\n",
    "        t_now += cfg.dt_sim\n",
    "\n",
    "    return logs, results\n",
    "\n",
    "\n",
    "def summarize_episode(logs: List[StepLog]) -> Dict[str, float]:\n",
    "    lambda2_vals = np.array([x.lambda2_current for x in logs], dtype=float)\n",
    "    partitions = np.array([x.partition_now for x in logs], dtype=bool)\n",
    "    runtimes = np.array([x.runtime_ms for x in logs], dtype=float)\n",
    "\n",
    "    out = {\n",
    "        \"mean_lambda2\": float(np.mean(lambda2_vals)) if len(lambda2_vals) else 0.0,\n",
    "        \"partition_count\": int(np.sum(partitions)),\n",
    "        \"partition_rate\": float(np.mean(partitions)) if len(partitions) else 0.0,\n",
    "        \"runtime_median_ms\": float(np.median(runtimes)) if len(runtimes) else 0.0,\n",
    "        \"runtime_iqr_low_ms\": float(np.percentile(runtimes, 25)) if len(runtimes) else 0.0,\n",
    "        \"runtime_iqr_high_ms\": float(np.percentile(runtimes, 75)) if len(runtimes) else 0.0,\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Simple benchmark (runtime vs n)\n",
    "# ============================================================\n",
    "\n",
    "def benchmark_runtime_vs_n(\n",
    "    base_cfg: ACLDConfig,\n",
    "    sizes: Iterable[int] = (50, 150, 500, 1000),\n",
    "    repeats: int = 200,\n",
    ") -> List[Dict[str, float]]:\n",
    "    rows: List[Dict[str, float]] = []\n",
    "\n",
    "    for n in sizes:\n",
    "        cfg = ACLDConfig(**{**base_cfg.__dict__, \"n_uavs\": int(n)})\n",
    "        rng = make_rng(cfg.seed + int(n))\n",
    "        state = SwarmState.random_init(cfg, rng)\n",
    "        acld = ACLDCore(cfg)\n",
    "\n",
    "        times_ms = np.zeros(repeats, dtype=float)\n",
    "        for k in range(repeats):\n",
    "            t0 = time.perf_counter()\n",
    "            _ = acld.run_acld(state)\n",
    "            t1 = time.perf_counter()\n",
    "            times_ms[k] = (t1 - t0) * 1000.0\n",
    "            # small random motion to avoid exact cache repetition\n",
    "            state.step_random_kinematics(cfg, rng)\n",
    "\n",
    "        row = {\n",
    "            \"n\": int(n),\n",
    "            \"pairs\": int(n * (n - 1) // 2),\n",
    "            \"median_ms\": float(np.median(times_ms)),\n",
    "            \"q1_ms\": float(np.percentile(times_ms, 25)),\n",
    "            \"q3_ms\": float(np.percentile(times_ms, 75)),\n",
    "            \"mean_ms\": float(np.mean(times_ms)),\n",
    "            \"p95_ms\": float(np.percentile(times_ms, 95)),\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Optional: one-step evaluation helper for PEW/FP style labels\n",
    "# ============================================================\n",
    "\n",
    "def connectivity_components_from_adjacency(A: np.ndarray) -> Tuple[int, np.ndarray]:\n",
    "    G = csr_matrix(A.astype(np.int8))\n",
    "    n_comp, labels = connected_components(G, directed=False, return_labels=True)\n",
    "    return int(n_comp), labels\n",
    "\n",
    "\n",
    "def edge_deletion_disconnects(A: np.ndarray, edge: Tuple[int, int]) -> bool:\n",
    "    i, j = edge\n",
    "    if A[i, j] == 0:\n",
    "        return False\n",
    "    A2 = A.copy()\n",
    "    A2[i, j] = 0\n",
    "    A2[j, i] = 0\n",
    "    n_comp_before, _ = connectivity_components_from_adjacency(A)\n",
    "    n_comp_after, _ = connectivity_components_from_adjacency(A2)\n",
    "    return n_comp_after > n_comp_before\n",
    "\n",
    "\n",
    "def approximate_edge_f1_on_predicted_graph(\n",
    "    A_pred_viable: np.ndarray,\n",
    "    flagged_edges: List[Tuple[int, int]],\n",
    "    sample_size: int = 200,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Approximate edge-level F1 by sampling edges and testing edge deletion connectivity impact.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(123)\n",
    "\n",
    "    n = A_pred_viable.shape[0]\n",
    "    edges = [(i, j) for i in range(n) for j in range(i + 1, n) if A_pred_viable[i, j] == 1]\n",
    "    if not edges:\n",
    "        return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
    "\n",
    "    if len(edges) > sample_size:\n",
    "        idx = rng.choice(len(edges), size=sample_size, replace=False)\n",
    "        sampled = [edges[k] for k in idx]\n",
    "    else:\n",
    "        sampled = edges\n",
    "\n",
    "    true_critical = set(e for e in sampled if edge_deletion_disconnects(A_pred_viable, e))\n",
    "    flagged = set(flagged_edges)\n",
    "\n",
    "    tp = len(true_critical & flagged)\n",
    "    fp = len(flagged - true_critical)\n",
    "    fn = len(true_critical - flagged)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073abc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Paper-style experiment + plotting suite (ACLD full eval)\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class ScenarioSpec:\n",
    "    name: str\n",
    "    cfg_overrides: Dict[str, object]\n",
    "    horizon_s: float = 10.0\n",
    "    seeds: Tuple[int, ...] = (42, 43, 44, 45, 46)\n",
    "    ebc_every_k_steps: int = 5  # exact EBC is expensive; evaluate every k-th step\n",
    "\n",
    "\n",
    "def _clone_cfg(base_cfg: ACLDConfig, **overrides) -> ACLDConfig:\n",
    "    d = dict(base_cfg.__dict__)\n",
    "    d.update(overrides)\n",
    "    return ACLDConfig(**d)\n",
    "\n",
    "\n",
    "def _ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def _save_rows_csv(path: str, rows: List[Dict[str, object]]) -> None:\n",
    "    _ensure_dir(os.path.dirname(path) or \".\")\n",
    "    if not rows:\n",
    "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "        return\n",
    "    keys = sorted({k for r in rows for k in r.keys()})\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=keys)\n",
    "        w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "\n",
    "def _save_json(path: str, obj: object) -> None:\n",
    "    _ensure_dir(os.path.dirname(path) or \".\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def _binary_confusion_metrics(y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
    "    yt = np.array(y_true, dtype=int)\n",
    "    yp = np.array(y_pred, dtype=int)\n",
    "    if yt.size == 0:\n",
    "        return dict(tp=0, fp=0, tn=0, fn=0, precision=0.0, recall=0.0, f1=0.0, fpr=0.0, tpr=0.0, acc=0.0)\n",
    "\n",
    "    tp = int(np.sum((yt == 1) & (yp == 1)))\n",
    "    fp = int(np.sum((yt == 0) & (yp == 1)))\n",
    "    tn = int(np.sum((yt == 0) & (yp == 0)))\n",
    "    fn = int(np.sum((yt == 1) & (yp == 0)))\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "    tpr = recall\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) else 0.0\n",
    "\n",
    "    return dict(tp=tp, fp=fp, tn=tn, fn=fn, precision=precision, recall=recall, f1=f1, fpr=fpr, tpr=tpr, acc=acc)\n",
    "\n",
    "\n",
    "def _nanmean(vals: List[float]) -> float:\n",
    "    if not vals:\n",
    "        return float(\"nan\")\n",
    "    a = np.array(vals, dtype=float)\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.nanmean(a))\n",
    "\n",
    "\n",
    "def _nanstd(vals: List[float]) -> float:\n",
    "    if not vals:\n",
    "        return float(\"nan\")\n",
    "    a = np.array(vals, dtype=float)\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.nanstd(a))\n",
    "\n",
    "\n",
    "def build_current_viable_adjacency(acld: ACLDCore, state: SwarmState, with_guard: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Current snapshot adjacency on V' (UAVs + optional GS), using theta_plus and optionally p_min guard.\n",
    "    \"\"\"\n",
    "    cfg = acld.cfg\n",
    "    n_uav = cfg.n_uavs\n",
    "    n_total = cfg.n_total\n",
    "    sidx = cfg.gs_index\n",
    "\n",
    "    d_cur_uav = acld._pairwise_uav_dist(state.pos)\n",
    "    _, _, theta_plus_uav = acld.adaptive_threshold_uav_uav(state, d_cur_uav)\n",
    "    s_cur_uav = acld.success_probability_uav_uav(d_cur_uav, pos_for_jammer=state.pos)\n",
    "\n",
    "    A = np.zeros((n_total, n_total), dtype=np.uint8)\n",
    "\n",
    "    mask_uav = (d_cur_uav <= theta_plus_uav)\n",
    "    if with_guard:\n",
    "        mask_uav &= (s_cur_uav >= cfg.p_min)\n",
    "    np.fill_diagonal(mask_uav, False)\n",
    "    A[:n_uav, :n_uav] = mask_uav.astype(np.uint8)\n",
    "\n",
    "    if cfg.include_ground_station:\n",
    "        d_cur_gs = acld._uav_gs_dist(state.pos)\n",
    "        _, _, theta_plus_gs = acld.adaptive_threshold_uav_gs(state, d_cur_uav)\n",
    "        s_cur_gs = acld.success_probability_uav_gs(d_cur_gs, state.pos)\n",
    "\n",
    "        for i in range(n_uav):\n",
    "            ok = bool(d_cur_gs[i] <= theta_plus_gs[i])\n",
    "            if with_guard:\n",
    "                ok = ok and bool(s_cur_gs[i] >= cfg.p_min)\n",
    "            if ok:\n",
    "                A[i, sidx] = 1\n",
    "                A[sidx, i] = 1\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def binary_lambda2_from_adjacency(A: np.ndarray) -> float:\n",
    "    D = np.diag(np.sum(A.astype(float), axis=1))\n",
    "    L = D - A.astype(float)\n",
    "    return ACLDCore.algebraic_connectivity_lambda2(L)\n",
    "\n",
    "\n",
    "def topk_ebc_edges(A: np.ndarray, k: int) -> List[Tuple[int, int]]:\n",
    "    if k <= 0:\n",
    "        return []\n",
    "    eb = ACLDCore.edge_betweenness_brandes_unweighted(A)\n",
    "    if not eb:\n",
    "        return []\n",
    "    ranked = sorted(eb.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return [e for e, _ in ranked[:k]]\n",
    "\n",
    "\n",
    "def _edge_f1_exact_vs_bridges(A_target: np.ndarray, flagged_edges: List[Tuple[int, int]]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Edge-level F1 where ground truth = bridges of target graph (exact).\n",
    "    \"\"\"\n",
    "    true_critical = set(ACLDCore.tarjan_bridges(A_target))\n",
    "    all_edges = set((i, j) for i in range(A_target.shape[0]) for j in range(i + 1, A_target.shape[0]) if A_target[i, j] == 1)\n",
    "    flagged = set(e for e in flagged_edges if e in all_edges)\n",
    "\n",
    "    tp = len(true_critical & flagged)\n",
    "    fp = len(flagged - true_critical)\n",
    "    fn = len(true_critical - flagged)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"tp\": tp, \"fp\": fp, \"fn\": fn}\n",
    "\n",
    "\n",
    "def run_evaluated_episode(\n",
    "    cfg: ACLDConfig,\n",
    "    horizon_s: float = 10.0,\n",
    "    seed: Optional[int] = None,\n",
    "    ebc_every_k_steps: int = 5,\n",
    "    compute_exact_edge_f1_for_n_leq: int = 220,\n",
    ") -> Tuple[List[Dict[str, object]], Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Runs one episode and evaluates one-step-ahead prediction/alerts vs actual next snapshot.\n",
    "    Returns:\n",
    "      step_rows: list of per-step dicts\n",
    "      episode_summary: dict\n",
    "    \"\"\"\n",
    "    rng = make_rng(cfg.seed if seed is None else seed)\n",
    "    state = SwarmState.random_init(cfg, rng)\n",
    "    acld = ACLDCore(cfg)\n",
    "\n",
    "    T = int(round(horizon_s / cfg.dt_sim))\n",
    "    step_rows: List[Dict[str, object]] = []\n",
    "\n",
    "    # For confusion metrics\n",
    "    y_true_partition_next: List[int] = []\n",
    "    yhat_acld: List[int] = []\n",
    "    yhat_tarjan_guard: List[int] = []\n",
    "    yhat_tarjan_geom: List[int] = []\n",
    "\n",
    "    e1_acld_list: List[float] = []\n",
    "    e1_tarjan_list: List[float] = []\n",
    "    e1_ebc_list: List[float] = []\n",
    "\n",
    "    t_now = 0.0\n",
    "    for t_idx in range(max(0, T - 1)):\n",
    "        t0 = time.perf_counter()\n",
    "        res = acld.run_acld(state)\n",
    "        t1 = time.perf_counter()\n",
    "        runtime_ms = (t1 - t0) * 1000.0\n",
    "\n",
    "        A_now_viable = build_current_viable_adjacency(acld, state, with_guard=True)\n",
    "        A_now_geom = build_current_viable_adjacency(acld, state, with_guard=False)\n",
    "\n",
    "        # Baselines at t\n",
    "        tarjan_guard_edges = ACLDCore.tarjan_bridges(A_now_viable)\n",
    "        tarjan_geom_edges = ACLDCore.tarjan_bridges(A_now_geom)\n",
    "\n",
    "        # EBC baseline (subsampled in time due cost)\n",
    "        do_ebc = (ebc_every_k_steps <= 1) or (t_idx % ebc_every_k_steps == 0)\n",
    "        ebc_edges = []\n",
    "        if do_ebc:\n",
    "            k_ebc = max(1, len(res.risky_inter)) if len(res.risky_inter) > 0 else 1\n",
    "            ebc_edges = topk_ebc_edges(A_now_viable, k=k_ebc)\n",
    "\n",
    "        # Advance one step to obtain actual next label/graph\n",
    "        next_state = state.copy()\n",
    "        next_state.step_random_kinematics(cfg, rng)\n",
    "\n",
    "        A_next_viable = build_current_viable_adjacency(acld, next_state, with_guard=True)\n",
    "        n_comp_next, _ = connectivity_components_from_adjacency(A_next_viable)\n",
    "        lambda2_next_bin = binary_lambda2_from_adjacency(A_next_viable)\n",
    "        lambda2_next_weighted = acld._build_current_weighted_graph(next_state)[2]\n",
    "        lambda2_next_weighted_val = ACLDCore.algebraic_connectivity_lambda2(lambda2_next_weighted)\n",
    "\n",
    "        # One-step partition label (binary)\n",
    "        # Positive if actual next viable graph is disconnected (components > 1)\n",
    "        y_true = 1 if n_comp_next > 1 else 0\n",
    "\n",
    "        # ACLD alert rule (early warning + predicted partition diagnostics)\n",
    "        acld_alert = int(\n",
    "            (len(res.risky_inter) > 0)\n",
    "            or (len(res.components) > 1)\n",
    "            or (res.lambda2_pred_viable < cfg.lambda2_partition_threshold)\n",
    "        )\n",
    "\n",
    "        tarjan_guard_alert = int(len(tarjan_guard_edges) > 0)\n",
    "        tarjan_geom_alert = int(len(tarjan_geom_edges) > 0)\n",
    "\n",
    "        y_true_partition_next.append(y_true)\n",
    "        yhat_acld.append(acld_alert)\n",
    "        yhat_tarjan_guard.append(tarjan_guard_alert)\n",
    "        yhat_tarjan_geom.append(tarjan_geom_alert)\n",
    "\n",
    "        # Edge-level F1 vs next-step bridges (exact for moderate n, approximate for larger n)\n",
    "        target_flagged_acld = sorted(set(res.risky_inter + res.risky_intra))\n",
    "        if cfg.n_total <= compute_exact_edge_f1_for_n_leq:\n",
    "            f1_acld = _edge_f1_exact_vs_bridges(A_next_viable, target_flagged_acld)[\"f1\"]\n",
    "            f1_tarjan = _edge_f1_exact_vs_bridges(A_next_viable, tarjan_guard_edges)[\"f1\"]\n",
    "            if do_ebc:\n",
    "                f1_ebc = _edge_f1_exact_vs_bridges(A_next_viable, ebc_edges)[\"f1\"]\n",
    "            else:\n",
    "                f1_ebc = np.nan\n",
    "        else:\n",
    "            f1_acld = approximate_edge_f1_on_predicted_graph(A_next_viable, target_flagged_acld, sample_size=200, rng=rng)[\"f1\"]\n",
    "            f1_tarjan = approximate_edge_f1_on_predicted_graph(A_next_viable, tarjan_guard_edges, sample_size=200, rng=rng)[\"f1\"]\n",
    "            if do_ebc:\n",
    "                f1_ebc = approximate_edge_f1_on_predicted_graph(A_next_viable, ebc_edges, sample_size=200, rng=rng)[\"f1\"]\n",
    "            else:\n",
    "                f1_ebc = np.nan\n",
    "\n",
    "        e1_acld_list.append(float(f1_acld))\n",
    "        e1_tarjan_list.append(float(f1_tarjan))\n",
    "        if do_ebc:\n",
    "            e1_ebc_list.append(float(f1_ebc))\n",
    "\n",
    "        step_rows.append(\n",
    "            {\n",
    "                \"t\": t_now,\n",
    "                \"step_idx\": t_idx,\n",
    "                \"runtime_ms\": runtime_ms,\n",
    "                \"lambda2_current_weighted\": float(res.lambda2_current),\n",
    "                \"lambda2_pred_viable_bin\": float(res.lambda2_pred_viable),\n",
    "                \"lambda2_next_viable_bin\": float(lambda2_next_bin),\n",
    "                \"lambda2_next_weighted\": float(lambda2_next_weighted_val),\n",
    "                \"n_components_pred_guar\": int(len(res.components)),\n",
    "                \"n_components_next_viable\": int(n_comp_next),\n",
    "                \"n_risky_inter\": int(len(res.risky_inter)),\n",
    "                \"n_risky_intra\": int(len(res.risky_intra)),\n",
    "                \"n_risky_s_uav\": int(len(res.risky_s_uav)),\n",
    "                \"n_risky_uav_uav\": int(len(res.risky_uav_uav)),\n",
    "                \"tarjan_guard_bridges\": int(len(tarjan_guard_edges)),\n",
    "                \"tarjan_geom_bridges\": int(len(tarjan_geom_edges)),\n",
    "                \"ebc_k\": int(len(ebc_edges)),\n",
    "                \"label_partition_next\": int(y_true),\n",
    "                \"alert_acld\": int(acld_alert),\n",
    "                \"alert_tarjan_guard\": int(tarjan_guard_alert),\n",
    "                \"alert_tarjan_geom\": int(tarjan_geom_alert),\n",
    "                \"edge_f1_acld_vs_next\": float(f1_acld),\n",
    "                \"edge_f1_tarjan_vs_next\": float(f1_tarjan),\n",
    "                \"edge_f1_ebc_vs_next\": float(f1_ebc) if do_ebc else np.nan,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # move to next state\n",
    "        state = next_state\n",
    "        t_now += cfg.dt_sim\n",
    "\n",
    "    m_acld = _binary_confusion_metrics(y_true_partition_next, yhat_acld)\n",
    "    m_tg = _binary_confusion_metrics(y_true_partition_next, yhat_tarjan_guard)\n",
    "    m_tgeom = _binary_confusion_metrics(y_true_partition_next, yhat_tarjan_geom)\n",
    "\n",
    "    runtimes = [r[\"runtime_ms\"] for r in step_rows]\n",
    "    summary = {\n",
    "        \"n_steps_eval\": int(len(step_rows)),\n",
    "        \"partition_next_rate\": float(np.mean(y_true_partition_next)) if y_true_partition_next else 0.0,\n",
    "        \"runtime_median_ms\": float(np.median(runtimes)) if runtimes else 0.0,\n",
    "        \"runtime_p95_ms\": float(np.percentile(runtimes, 95)) if runtimes else 0.0,\n",
    "        \"mean_lambda2_current_weighted\": float(np.mean([r[\"lambda2_current_weighted\"] for r in step_rows])) if step_rows else 0.0,\n",
    "\n",
    "        # ACLD confusion\n",
    "        \"acld_precision\": m_acld[\"precision\"],\n",
    "        \"acld_recall\": m_acld[\"recall\"],\n",
    "        \"acld_f1\": m_acld[\"f1\"],\n",
    "        \"acld_fpr\": m_acld[\"fpr\"],\n",
    "        \"acld_acc\": m_acld[\"acc\"],\n",
    "\n",
    "        # Tarjan guard\n",
    "        \"tarjan_guard_precision\": m_tg[\"precision\"],\n",
    "        \"tarjan_guard_recall\": m_tg[\"recall\"],\n",
    "        \"tarjan_guard_f1\": m_tg[\"f1\"],\n",
    "        \"tarjan_guard_fpr\": m_tg[\"fpr\"],\n",
    "        \"tarjan_guard_acc\": m_tg[\"acc\"],\n",
    "\n",
    "        # Tarjan geom-only\n",
    "        \"tarjan_geom_precision\": m_tgeom[\"precision\"],\n",
    "        \"tarjan_geom_recall\": m_tgeom[\"recall\"],\n",
    "        \"tarjan_geom_f1\": m_tgeom[\"f1\"],\n",
    "        \"tarjan_geom_fpr\": m_tgeom[\"fpr\"],\n",
    "        \"tarjan_geom_acc\": m_tgeom[\"acc\"],\n",
    "\n",
    "        # Edge F1\n",
    "        \"edge_f1_acld_mean\": _nanmean(e1_acld_list),\n",
    "        \"edge_f1_tarjan_mean\": _nanmean(e1_tarjan_list),\n",
    "        \"edge_f1_ebc_mean\": _nanmean(e1_ebc_list),\n",
    "    }\n",
    "    return step_rows, summary\n",
    "\n",
    "\n",
    "def run_scenario_mc(\n",
    "    base_cfg: ACLDConfig,\n",
    "    spec: ScenarioSpec,\n",
    ") -> Tuple[List[Dict[str, object]], List[Dict[str, object]], Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      scenario_episode_rows (one row per seed),\n",
    "      scenario_step_rows (all steps, tagged),\n",
    "      aggregated_summary\n",
    "    \"\"\"\n",
    "    cfg = _clone_cfg(base_cfg, **spec.cfg_overrides)\n",
    "\n",
    "    episode_rows: List[Dict[str, object]] = []\n",
    "    all_step_rows: List[Dict[str, object]] = []\n",
    "\n",
    "    for seed in spec.seeds:\n",
    "        step_rows, ep_summary = run_evaluated_episode(\n",
    "            cfg=cfg,\n",
    "            horizon_s=spec.horizon_s,\n",
    "            seed=seed,\n",
    "            ebc_every_k_steps=spec.ebc_every_k_steps,\n",
    "        )\n",
    "        ep_row = {\n",
    "            \"scenario\": spec.name,\n",
    "            \"seed\": seed,\n",
    "            \"n_uavs\": cfg.n_uavs,\n",
    "            \"density_scale_mode\": cfg.density_scale_mode,\n",
    "            \"jnr_db\": cfg.jnr_db if cfg.jnr_db is not None else \"None\",\n",
    "            **ep_summary,\n",
    "        }\n",
    "        episode_rows.append(ep_row)\n",
    "\n",
    "        for r in step_rows:\n",
    "            rr = dict(r)\n",
    "            rr[\"scenario\"] = spec.name\n",
    "            rr[\"seed\"] = seed\n",
    "            rr[\"n_uavs\"] = cfg.n_uavs\n",
    "            rr[\"density_scale_mode\"] = cfg.density_scale_mode\n",
    "            rr[\"jnr_db\"] = cfg.jnr_db if cfg.jnr_db is not None else \"None\"\n",
    "            all_step_rows.append(rr)\n",
    "\n",
    "    # Aggregate across seeds\n",
    "    def _agg(key: str) -> Tuple[float, float]:\n",
    "        vals = [float(r[key]) for r in episode_rows if key in r and r[key] == r[key]]\n",
    "        if not vals:\n",
    "            return float(\"nan\"), float(\"nan\")\n",
    "        return float(np.mean(vals)), float(np.std(vals))\n",
    "\n",
    "    agg = {\n",
    "        \"scenario\": spec.name,\n",
    "        \"n_episodes\": len(episode_rows),\n",
    "        \"n_uavs\": cfg.n_uavs,\n",
    "        \"density_scale_mode\": cfg.density_scale_mode,\n",
    "        \"jnr_db\": cfg.jnr_db if cfg.jnr_db is not None else \"None\",\n",
    "    }\n",
    "\n",
    "    keys_to_aggregate = [\n",
    "        \"partition_next_rate\",\n",
    "        \"runtime_median_ms\",\n",
    "        \"runtime_p95_ms\",\n",
    "        \"mean_lambda2_current_weighted\",\n",
    "        \"acld_precision\", \"acld_recall\", \"acld_f1\", \"acld_fpr\", \"acld_acc\",\n",
    "        \"tarjan_guard_precision\", \"tarjan_guard_recall\", \"tarjan_guard_f1\", \"tarjan_guard_fpr\", \"tarjan_guard_acc\",\n",
    "        \"tarjan_geom_precision\", \"tarjan_geom_recall\", \"tarjan_geom_f1\", \"tarjan_geom_fpr\", \"tarjan_geom_acc\",\n",
    "        \"edge_f1_acld_mean\", \"edge_f1_tarjan_mean\", \"edge_f1_ebc_mean\",\n",
    "    ]\n",
    "\n",
    "    for k in keys_to_aggregate:\n",
    "        mu, sd = _agg(k)\n",
    "        agg[f\"{k}_mean\"] = mu\n",
    "        agg[f\"{k}_std\"] = sd\n",
    "\n",
    "    return episode_rows, all_step_rows, agg\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Plotting helpers\n",
    "# --------------------------\n",
    "\n",
    "def _plot_timeseries_representative(step_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not step_rows:\n",
    "        return\n",
    "\n",
    "    t = np.array([r[\"t\"] for r in step_rows], dtype=float)\n",
    "    lam = np.array([r[\"lambda2_current_weighted\"] for r in step_rows], dtype=float)\n",
    "    lam_pred = np.array([r[\"lambda2_pred_viable_bin\"] for r in step_rows], dtype=float)\n",
    "    lam_next = np.array([r[\"lambda2_next_viable_bin\"] for r in step_rows], dtype=float)\n",
    "    r_inter = np.array([r[\"n_risky_inter\"] for r in step_rows], dtype=float)\n",
    "    r_intra = np.array([r[\"n_risky_intra\"] for r in step_rows], dtype=float)\n",
    "    r_s = np.array([r[\"n_risky_s_uav\"] for r in step_rows], dtype=float)\n",
    "    r_uu = np.array([r[\"n_risky_uav_uav\"] for r in step_rows], dtype=float)\n",
    "    comp_pred = np.array([r[\"n_components_pred_guar\"] for r in step_rows], dtype=float)\n",
    "    comp_next = np.array([r[\"n_components_next_viable\"] for r in step_rows], dtype=float)\n",
    "    rt = np.array([r[\"runtime_ms\"] for r in step_rows], dtype=float)\n",
    "    y = np.array([r[\"label_partition_next\"] for r in step_rows], dtype=float)\n",
    "\n",
    "    # Figure 1: lambda2 trends\n",
    "    plt.figure(figsize=(10, 4.8))\n",
    "    plt.plot(t, lam, label=\"λ2 current (weighted)\")\n",
    "    plt.plot(t, lam_pred, label=\"λ2 pred viable (binary)\")\n",
    "    plt.plot(t, lam_next, label=\"λ2 next viable (binary)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Connectivity metric\")\n",
    "    plt.title(\"Connectivity traces over time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_01_lambda2_timeseries.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # Figure 2: risky link counts\n",
    "    plt.figure(figsize=(10, 4.8))\n",
    "    plt.plot(t, r_inter, label=\"risky inter\")\n",
    "    plt.plot(t, r_intra, label=\"risky intra\")\n",
    "    plt.plot(t, r_s, label=\"risky S-UAV\")\n",
    "    plt.plot(t, r_uu, label=\"risky UAV-UAV\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Risky link counts over time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_02_risky_link_counts.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # Figure 3: component counts + partition label\n",
    "    plt.figure(figsize=(10, 4.8))\n",
    "    plt.plot(t, comp_pred, label=\"pred guaranteed components\")\n",
    "    plt.plot(t, comp_next, label=\"next viable components\")\n",
    "    plt.step(t, y, where=\"post\", label=\"partition label (next)\", alpha=0.8)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Count / label\")\n",
    "    plt.title(\"Predicted vs actual next-step partition behavior\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_03_components_partition_label.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # Figure 4: runtime\n",
    "    plt.figure(figsize=(10, 4.8))\n",
    "    plt.plot(t, rt)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.title(\"ACLD per-step runtime\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_04_runtime_timeseries.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_runtime_scaling(bench_rows: List[Dict[str, float]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not bench_rows:\n",
    "        return\n",
    "    n = np.array([r[\"n\"] for r in bench_rows], dtype=float)\n",
    "    med = np.array([r[\"median_ms\"] for r in bench_rows], dtype=float)\n",
    "    q1 = np.array([r[\"q1_ms\"] for r in bench_rows], dtype=float)\n",
    "    q3 = np.array([r[\"q3_ms\"] for r in bench_rows], dtype=float)\n",
    "    p95 = np.array([r[\"p95_ms\"] for r in bench_rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(n, med, marker=\"o\", label=\"Median\")\n",
    "    plt.fill_between(n, q1, q3, alpha=0.2, label=\"IQR\")\n",
    "    plt.plot(n, p95, marker=\"s\", linestyle=\"--\", label=\"P95\")\n",
    "    plt.xlabel(\"Number of UAVs\")\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.title(\"Runtime scaling vs swarm size\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_05_runtime_scaling.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_scenario_bars(agg_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not agg_rows:\n",
    "        return\n",
    "    names = [str(r[\"scenario\"]) for r in agg_rows]\n",
    "    x = np.arange(len(names), dtype=float)\n",
    "    w = 0.23\n",
    "\n",
    "    acld_f1 = np.array([float(r.get(\"acld_f1_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    tg_f1 = np.array([float(r.get(\"tarjan_guard_f1_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    tgeom_f1 = np.array([float(r.get(\"tarjan_geom_f1_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(max(9, 1.2 * len(names)), 5.2))\n",
    "    plt.bar(x - w, acld_f1, width=w, label=\"ACLD\")\n",
    "    plt.bar(x, tg_f1, width=w, label=\"Tarjan+guard\")\n",
    "    plt.bar(x + w, tgeom_f1, width=w, label=\"Tarjan geom-only\")\n",
    "    plt.xticks(x, names, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"F1 (partition early warning)\")\n",
    "    plt.title(\"PEW F1 across scenarios\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_06_pew_f1_scenarios.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # FPR comparison\n",
    "    acld_fpr = np.array([float(r.get(\"acld_fpr_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    tg_fpr = np.array([float(r.get(\"tarjan_guard_fpr_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    tgeom_fpr = np.array([float(r.get(\"tarjan_geom_fpr_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(max(9, 1.2 * len(names)), 5.2))\n",
    "    plt.bar(x - w, acld_fpr, width=w, label=\"ACLD\")\n",
    "    plt.bar(x, tg_fpr, width=w, label=\"Tarjan+guard\")\n",
    "    plt.bar(x + w, tgeom_fpr, width=w, label=\"Tarjan geom-only\")\n",
    "    plt.xticks(x, names, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"False Positive Rate\")\n",
    "    plt.title(\"False-positive behavior across scenarios\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_07_fpr_scenarios.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # Edge F1 comparison\n",
    "    acld_e = np.array([float(r.get(\"edge_f1_acld_mean_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    tg_e = np.array([float(r.get(\"edge_f1_tarjan_mean_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "    ebc_e = np.array([float(r.get(\"edge_f1_ebc_mean_mean\", np.nan)) for r in agg_rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(max(9, 1.2 * len(names)), 5.2))\n",
    "    plt.bar(x - w, acld_e, width=w, label=\"ACLD\")\n",
    "    plt.bar(x, tg_e, width=w, label=\"Tarjan+guard\")\n",
    "    plt.bar(x + w, ebc_e, width=w, label=\"EBC@t top-k\")\n",
    "    plt.xticks(x, names, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Edge-level F1 (vs next bridges)\")\n",
    "    plt.title(\"Edge-level critical-link prediction quality\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_08_edge_f1_scenarios.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_runtime_boxplot_per_scenario(episode_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not episode_rows:\n",
    "        return\n",
    "    by_s: Dict[str, List[float]] = {}\n",
    "    for r in episode_rows:\n",
    "        by_s.setdefault(str(r[\"scenario\"]), []).append(float(r[\"runtime_median_ms\"]))\n",
    "    names = list(by_s.keys())\n",
    "    data = [by_s[k] for k in names]\n",
    "\n",
    "    plt.figure(figsize=(max(8, 1.1 * len(names)), 5))\n",
    "    plt.boxplot(data, labels=names, showmeans=True)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Episode median runtime (ms)\")\n",
    "    plt.title(\"Runtime distribution across scenarios/seeds\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_09_runtime_boxplot_scenarios.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_jamming_sweep(jam_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not jam_rows:\n",
    "        return\n",
    "    # sort by jnr\n",
    "    def _jnr_key(v):\n",
    "        x = v[\"jnr_db\"]\n",
    "        return -1 if x == \"None\" else float(x)\n",
    "    rows = sorted(jam_rows, key=_jnr_key)\n",
    "\n",
    "    x = []\n",
    "    labels = []\n",
    "    for r in rows:\n",
    "        labels.append(str(r[\"jnr_db\"]))\n",
    "        x.append(len(x))\n",
    "    x = np.array(x, dtype=float)\n",
    "\n",
    "    lam = np.array([float(r[\"mean_lambda2_current_weighted_mean\"]) for r in rows], dtype=float)\n",
    "    part = np.array([float(r[\"partition_next_rate_mean\"]) for r in rows], dtype=float)\n",
    "    acld_f1 = np.array([float(r[\"acld_f1_mean\"]) for r in rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.plot(x, lam, marker=\"o\", label=\"mean λ2 (weighted)\")\n",
    "    plt.plot(x, part, marker=\"s\", label=\"partition-next rate\")\n",
    "    plt.plot(x, acld_f1, marker=\"^\", label=\"ACLD PEW F1\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.xlabel(\"JNR (dB) [None=nominal]\")\n",
    "    plt.ylabel(\"Metric value\")\n",
    "    plt.title(\"Jamming stress sweep\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_10_jamming_sweep.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_density_sweep(density_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not density_rows:\n",
    "        return\n",
    "    order = {\"sparse\": 0, \"medium\": 1, \"dense\": 2}\n",
    "    rows = sorted(density_rows, key=lambda r: order.get(str(r[\"density_scale_mode\"]), 999))\n",
    "    names = [str(r[\"density_scale_mode\"]) for r in rows]\n",
    "    x = np.arange(len(names), dtype=float)\n",
    "\n",
    "    part = np.array([float(r[\"partition_next_rate_mean\"]) for r in rows], dtype=float)\n",
    "    acld_f1 = np.array([float(r[\"acld_f1_mean\"]) for r in rows], dtype=float)\n",
    "    fpr = np.array([float(r[\"acld_fpr_mean\"]) for r in rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, part, marker=\"o\", label=\"partition-next rate\")\n",
    "    plt.plot(x, acld_f1, marker=\"s\", label=\"ACLD PEW F1\")\n",
    "    plt.plot(x, fpr, marker=\"^\", label=\"ACLD FPR\")\n",
    "    plt.xticks(x, names)\n",
    "    plt.xlabel(\"Density mode\")\n",
    "    plt.ylabel(\"Metric value\")\n",
    "    plt.title(\"Density sweep\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_11_density_sweep.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_ablation(ablation_rows: List[Dict[str, object]], outdir: str, prefix: str = \"fig\") -> None:\n",
    "    if not ablation_rows:\n",
    "        return\n",
    "    names = [str(r[\"scenario\"]) for r in ablation_rows]\n",
    "    x = np.arange(len(names), dtype=float)\n",
    "    acld_f1 = np.array([float(r[\"acld_f1_mean\"]) for r in ablation_rows], dtype=float)\n",
    "    acld_fpr = np.array([float(r[\"acld_fpr_mean\"]) for r in ablation_rows], dtype=float)\n",
    "    edge_f1 = np.array([float(r[\"edge_f1_acld_mean_mean\"]) for r in ablation_rows], dtype=float)\n",
    "\n",
    "    plt.figure(figsize=(max(9, 1.2 * len(names)), 5))\n",
    "    plt.plot(x, acld_f1, marker=\"o\", label=\"ACLD PEW F1\")\n",
    "    plt.plot(x, acld_fpr, marker=\"s\", label=\"ACLD FPR\")\n",
    "    plt.plot(x, edge_f1, marker=\"^\", label=\"ACLD edge F1\")\n",
    "    plt.xticks(x, names, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(\"Ablation study (adaptive terms)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{prefix}_12_ablation.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Full paper-like suite\n",
    "# --------------------------\n",
    "\n",
    "def run_full_paper_suite(\n",
    "    outdir: str = \"acld_paper_outputs\",\n",
    "    base_cfg: Optional[ACLDConfig] = None,\n",
    "    fast_mode: bool = False,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Generates:\n",
    "      - representative episode timeseries plots\n",
    "      - scenario MC summaries + plots\n",
    "      - runtime scaling benchmark\n",
    "      - jamming sweep / density sweep\n",
    "      - ablation study\n",
    "      - CSV + JSON outputs\n",
    "    \"\"\"\n",
    "    _ensure_dir(outdir)\n",
    "    figdir = os.path.join(outdir, \"figures\")\n",
    "    tabdir = os.path.join(outdir, \"tables\")\n",
    "    rawdir = os.path.join(outdir, \"raw\")\n",
    "    for d in (figdir, tabdir, rawdir):\n",
    "        _ensure_dir(d)\n",
    "\n",
    "    if base_cfg is None:\n",
    "        base_cfg = ACLDConfig(\n",
    "            n_uavs=150,\n",
    "            include_ground_station=True,\n",
    "            density_scale_mode=\"medium\",\n",
    "            jnr_db=None,\n",
    "            seed=42,\n",
    "        )\n",
    "\n",
    "    # Speed presets\n",
    "    if fast_mode:\n",
    "        rep_horizon = 5.0\n",
    "        mc_horizon = 6.0\n",
    "        seeds_small = (42, 43, 44)\n",
    "        repeats_bench = 20\n",
    "        bench_sizes = (50, 150, 300)\n",
    "    else:\n",
    "        rep_horizon = 15.0\n",
    "        mc_horizon = 12.0\n",
    "        seeds_small = (42, 43, 44, 45, 46)\n",
    "        repeats_bench = 60\n",
    "        bench_sizes = (50, 150, 300, 500)\n",
    "\n",
    "    # 1) Representative episode (timeseries figures)\n",
    "    rep_spec = ScenarioSpec(\n",
    "        name=\"representative_nominal\",\n",
    "        cfg_overrides=dict(jnr_db=None, density_scale_mode=\"medium\"),\n",
    "        horizon_s=rep_horizon,\n",
    "        seeds=(base_cfg.seed,),\n",
    "        ebc_every_k_steps=5,\n",
    "    )\n",
    "    rep_ep_rows, rep_step_rows, rep_agg = run_scenario_mc(base_cfg, rep_spec)\n",
    "    _save_rows_csv(os.path.join(rawdir, \"representative_episode_summary.csv\"), rep_ep_rows)\n",
    "    _save_rows_csv(os.path.join(rawdir, \"representative_episode_steps.csv\"), rep_step_rows)\n",
    "    _save_json(os.path.join(rawdir, \"representative_episode_agg.json\"), rep_agg)\n",
    "    # Only first seed representative rows\n",
    "    rep_seed_rows = [r for r in rep_step_rows if int(r[\"seed\"]) == int(base_cfg.seed)]\n",
    "    rep_seed_rows = sorted(rep_seed_rows, key=lambda r: float(r[\"t\"]))\n",
    "    _plot_timeseries_representative(rep_seed_rows, figdir)\n",
    "\n",
    "    # 2) Main scenario set (nominal / jamming / density)\n",
    "    scenarios = [\n",
    "        ScenarioSpec(\"nominal_medium\", dict(jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"jam_5dB_medium\", dict(jnr_db=5.0, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"jam_15dB_medium\", dict(jnr_db=15.0, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"nominal_sparse\", dict(jnr_db=None, density_scale_mode=\"sparse\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"nominal_dense\", dict(jnr_db=None, density_scale_mode=\"dense\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "    ]\n",
    "\n",
    "    all_episode_rows: List[Dict[str, object]] = []\n",
    "    all_step_rows: List[Dict[str, object]] = []\n",
    "    agg_rows: List[Dict[str, object]] = []\n",
    "\n",
    "    for spec in scenarios:\n",
    "        ep_rows, st_rows, agg = run_scenario_mc(base_cfg, spec)\n",
    "        all_episode_rows.extend(ep_rows)\n",
    "        all_step_rows.extend(st_rows)\n",
    "        agg_rows.append(agg)\n",
    "\n",
    "    _save_rows_csv(os.path.join(tabdir, \"scenario_episode_metrics.csv\"), all_episode_rows)\n",
    "    _save_rows_csv(os.path.join(rawdir, \"scenario_step_metrics.csv\"), all_step_rows)\n",
    "    _save_rows_csv(os.path.join(tabdir, \"scenario_aggregated_summary.csv\"), agg_rows)\n",
    "\n",
    "    _plot_scenario_bars(agg_rows, figdir)\n",
    "    _plot_runtime_boxplot_per_scenario(all_episode_rows, figdir)\n",
    "\n",
    "    # 3) Runtime scaling benchmark\n",
    "    bench_rows = benchmark_runtime_vs_n(base_cfg, sizes=bench_sizes, repeats=repeats_bench)\n",
    "    _save_rows_csv(os.path.join(tabdir, \"runtime_scaling.csv\"), bench_rows)\n",
    "    _plot_runtime_scaling(bench_rows, figdir)\n",
    "\n",
    "    # 4) Jamming sweep\n",
    "    jam_specs = [\n",
    "        ScenarioSpec(f\"jnr_{'nominal' if j is None else str(int(j))+'dB'}\",\n",
    "                     dict(jnr_db=j, density_scale_mode=\"medium\"),\n",
    "                     horizon_s=mc_horizon, seeds=seeds_small)\n",
    "        for j in (None, 0.0, 5.0, 10.0, 15.0, 20.0)\n",
    "    ]\n",
    "    jam_agg_rows = []\n",
    "    for spec in jam_specs:\n",
    "        _, _, agg = run_scenario_mc(base_cfg, spec)\n",
    "        jam_agg_rows.append(agg)\n",
    "    _save_rows_csv(os.path.join(tabdir, \"jamming_sweep_summary.csv\"), jam_agg_rows)\n",
    "    _plot_jamming_sweep(jam_agg_rows, figdir)\n",
    "\n",
    "    # 5) Density sweep\n",
    "    density_specs = [\n",
    "        ScenarioSpec(f\"density_{mode}\", dict(jnr_db=None, density_scale_mode=mode),\n",
    "                     horizon_s=mc_horizon, seeds=seeds_small)\n",
    "        for mode in (\"sparse\", \"medium\", \"dense\")\n",
    "    ]\n",
    "    density_agg_rows = []\n",
    "    for spec in density_specs:\n",
    "        _, _, agg = run_scenario_mc(base_cfg, spec)\n",
    "        density_agg_rows.append(agg)\n",
    "    _save_rows_csv(os.path.join(tabdir, \"density_sweep_summary.csv\"), density_agg_rows)\n",
    "    _plot_density_sweep(density_agg_rows, figdir)\n",
    "\n",
    "    # 6) Ablation study (adaptive terms)\n",
    "    ablation_specs = [\n",
    "        ScenarioSpec(\"ablation_full\", dict(jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_no_alpha\", dict(alpha=0.0, jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_no_beta\", dict(beta=0.0, jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_no_gamma\", dict(gamma=0.0, jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_no_delta\", dict(delta=0.0, jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_no_zeta\", dict(zeta=0.0, jnr_db=None, density_scale_mode=\"medium\"), horizon_s=mc_horizon, seeds=seeds_small),\n",
    "        ScenarioSpec(\"ablation_fixed_cthr\", dict(alpha=0.0, beta=0.0, gamma=0.0, delta=0.0, zeta=0.0,\n",
    "                                                 jnr_db=None, density_scale_mode=\"medium\"),\n",
    "                     horizon_s=mc_horizon, seeds=seeds_small),\n",
    "    ]\n",
    "    ablation_agg_rows = []\n",
    "    for spec in ablation_specs:\n",
    "        _, _, agg = run_scenario_mc(base_cfg, spec)\n",
    "        ablation_agg_rows.append(agg)\n",
    "    _save_rows_csv(os.path.join(tabdir, \"ablation_summary.csv\"), ablation_agg_rows)\n",
    "    _plot_ablation(ablation_agg_rows, figdir)\n",
    "\n",
    "    # 7) Compact summary JSON\n",
    "    summary = {\n",
    "        \"outdir\": outdir,\n",
    "        \"fast_mode\": fast_mode,\n",
    "        \"base_cfg\": {\n",
    "            \"n_uavs\": base_cfg.n_uavs,\n",
    "            \"include_ground_station\": base_cfg.include_ground_station,\n",
    "            \"density_scale_mode\": base_cfg.density_scale_mode,\n",
    "            \"jnr_db\": base_cfg.jnr_db,\n",
    "            \"seed\": base_cfg.seed,\n",
    "            \"p_min\": base_cfg.p_min,\n",
    "        },\n",
    "        \"files\": {\n",
    "            \"figures_dir\": figdir,\n",
    "            \"tables_dir\": tabdir,\n",
    "            \"raw_dir\": rawdir,\n",
    "        },\n",
    "        \"n_main_scenarios\": len(scenarios),\n",
    "        \"n_jam_sweep_points\": len(jam_specs),\n",
    "        \"n_density_sweep_points\": len(density_specs),\n",
    "        \"n_ablations\": len(ablation_specs),\n",
    "    }\n",
    "    _save_json(os.path.join(outdir, \"suite_summary.json\"), summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Demo main\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Tam deney paketi (hızlı test)\n",
    "    summary = run_full_paper_suite(\n",
    "        outdir=\"acld_paper_outputs\",\n",
    "        base_cfg=ACLDConfig(\n",
    "            n_uavs=150,\n",
    "            include_ground_station=True,\n",
    "            density_scale_mode=\"medium\",\n",
    "            jnr_db=None,\n",
    "            seed=42,\n",
    "        ),\n",
    "        fast_mode=True,   # önce True ile test edin, sonra False\n",
    "    )\n",
    "    print(\"Suite summary:\")\n",
    "    print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "\n",
    "\"\"\"if __name__ == \"__main__\":\n",
    "    # Example 1: single episode demo\n",
    "    cfg = ACLDConfig(\n",
    "        n_uavs=50,\n",
    "        include_ground_station=True,\n",
    "        density_scale_mode=\"medium\",\n",
    "        jnr_db=None,   # nominal\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    logs, results = run_episode(cfg, horizon_s=2.0, seed=42)\n",
    "    summary = summarize_episode(logs)\n",
    "\n",
    "    print(\"=== ACLD Episode Summary ===\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    last = results[-1]\n",
    "    print(\"\\n=== Last-step diagnostics ===\")\n",
    "    print(f\"lambda2_current      : {last.lambda2_current:.6f}\")\n",
    "    print(f\"lambda2_pred_viable  : {last.lambda2_pred_viable:.6f}\")\n",
    "    print(f\"pred components (guar): {len(last.components)}\")\n",
    "    print(f\"risky_inter          : {len(last.risky_inter)}\")\n",
    "    print(f\"risky_intra          : {len(last.risky_intra)}\")\n",
    "    print(f\"risky_s_uav          : {len(last.risky_s_uav)}\")\n",
    "    print(f\"risky_uav_uav        : {len(last.risky_uav_uav)}\")\n",
    "\n",
    "    # Example 2: runtime benchmark (small repeats for demo)\n",
    "    print(\"\\n=== Runtime benchmark (demo repeats=20) ===\")\n",
    "    bench_rows = benchmark_runtime_vs_n(cfg, sizes=(50, 150, 300), repeats=20)\n",
    "    for row in bench_rows:\n",
    "        print(row) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
